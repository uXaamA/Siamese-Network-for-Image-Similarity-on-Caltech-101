# ğŸ§  Siamese Network for Image Similarity on Caltech-101 Dataset

This project implements a **Siamese Neural Network** from scratch using **PyTorch**, built for **learning image similarity** between pairs of images. The model was trained and evaluated on the **Caltech-101** dataset and uses a **contrastive loss function** to learn an embedding space where similar images are close together, and dissimilar ones are far apart.

---

## ğŸ¯ Objective

The primary goal of this project is to train a **deep learning model that can tell whether two images belong to the same class or not** â€” without relying on classification directly. This approach is widely used in:
- Face verification (e.g., Face ID)
- Signature verification
- Product similarity in e-commerce
- Image retrieval

---

## ğŸ“‚ Project Structure
project/
- â”œâ”€â”€ rollNumber_02_task1.py # End-to-end integration script (training, testing, visualization)
- â”œâ”€â”€ train.py # Training loop and checkpointing
- â”œâ”€â”€ test.py # Evaluation script
- â”œâ”€â”€ model.py # Siamese network class using ResNet-50
- â”œâ”€â”€ data_utils.py # Dataset class and custom dataloader for image pairs
- â”œâ”€â”€ weights/ # Directory to store trained model weights
- â”œâ”€â”€ graphs/ # Visualizations (loss curves, confusion matrix, etc.)
- â”œâ”€â”€ Report.pdf # Final report with training analysis
- â”œâ”€â”€ requirements.txt # Project dependencies
- â””â”€â”€ README.md # You are here ğŸ“˜



---

## ğŸ—ƒ Dataset: Caltech-101

- Contains **9,145 images** across **102 classes**
- Classes include objects like helicopters, faces, animals, instruments, etc.
- Dataset is stored in a **single directory**, so we wrote a **custom split function** to separate into:
  - `Train` set
  - `Validation` set
  - `Test` set  
- Splitting preserves **class ratios** to maintain balance.

ğŸ“ **Reference**: [Caltech-101 Dataset Page](https://data.caltech.edu/records/mzrjq-6wc02)

---

## ğŸ”€ Data Preparation & Preprocessing

- Each training sample is a **pair of images**
- Label is `0` if the two images are similar (same class), and `1` if dissimilar (different classes)
- To avoid imbalance, we sample an equal number of positive and negative pairs
- **Transforms** applied:
```python
transforms.Compose([
    transforms.Resize(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
]) ```
```


## ğŸ“ What the Model Learns

Rather than learning â€œwhat is a tiger?â€, the model learns:
- â€œHow similar are two things in their deep visual patterns?â€

Thatâ€™s powerful because:
- It doesnâ€™t rely on labeled classes during inference
- It generalizes to *any* pair â€” even unseen categories

---

## ğŸ“Œ Contrastive Loss â€” Mathematical Form

We use **contrastive loss** to train the network:

\[
L = \frac{1}{2N} \sum_{i=1}^N \left[ y_i \cdot d_i^2 + (1 - y_i) \cdot \max(\alpha - d_i, 0)^2 \right]
\]

Where:

- \( y_i \in \{0, 1\} \):  
   - 0 â†’ same class  
   - 1 â†’ different class  
- \( d_i = \| e_{a_i} - e_{p_i} \|_2 \): Euclidean distance between embeddings
- \( \alpha \): margin (usually set to 1.0)

This loss:
- Reduces distance between similar image pairs
- Increases distance for dissimilar pairs (up to margin)

---

ğŸ‘¤ Author
Muhammad Usama
ğŸ“ MS Data Science â€” Information Technology Lahore
âš™ï¸ Technical Data Analyst, Haier Pakistan
ğŸ§  Passion: AI | ML | Computer Vision | Startups
ğŸ”¥ Founder: Phantomwears Clothing
ğŸ“§ usaman3244015@gmail.com
ğŸ“ Lahore, Pakistan
